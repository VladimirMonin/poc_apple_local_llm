"""
–ú–æ–¥—É–ª—å –ø–æ–∏—Å–∫–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π.
"""

from typing import List, Dict, Tuple
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity


class VectorSearch:
    """–ü–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞."""

    @staticmethod
    def search(
        query_vector: np.ndarray,
        database_vectors: np.ndarray,
        database_metadata: List[Dict],
        top_k: int = 5,
        threshold: float = 0.0,
    ) -> List[Tuple[Dict, float]]:
        """
        –ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π.

        Args:
            query_vector: –í–µ–∫—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞ (1D numpy array)
            database_vectors: –ú–∞—Å—Å–∏–≤ –≤–µ–∫—Ç–æ—Ä–æ–≤ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (2D numpy array)
            database_metadata: –°–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
            threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ (0.0-1.0)

        Returns:
            List[(metadata, similarity_score)] –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        """
        if database_vectors is None or len(database_vectors) == 0:
            return []

        # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ query_vector 2D –¥–ª—è sklearn
        query_vector = query_vector.reshape(1, -1)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
        similarities = cosine_similarity(query_vector, database_vectors)[0]

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä (–∏–Ω–¥–µ–∫—Å, —Å—Ö–æ–¥—Å—Ç–≤–æ)
        results = [
            (idx, score)
            for idx, score in enumerate(similarities)
            if score >= threshold
        ]

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        results.sort(key=lambda x: x[1], reverse=True)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ top_k
        results = results[:top_k]

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        final_results = [
            (database_metadata[idx], score) for idx, score in results
        ]

        return final_results

    @staticmethod
    def format_results(results: List[Tuple[Dict, float]]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞.

        Args:
            results: –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ search()

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
        """
        if not results:
            return "‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"

        output = []
        output.append(f"\nüìä –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}\n")

        for i, (metadata, score) in enumerate(results, 1):
            output.append("=" * 70)
            output.append(f"#{i} | –°—Ö–æ–¥—Å—Ç–≤–æ: {score * 100:.2f}%")
            output.append("=" * 70)
            output.append(f"üìÖ –î–∞—Ç–∞: {metadata['timestamp']}")
            output.append(f"üñºÔ∏è  –°–∫—Ä–∏–Ω—à–æ—Ç: {metadata['screenshot_path']}")
            output.append(f"üìù –¢–µ–∫—Å—Ç ({metadata['text_length']} —Å–∏–º–≤–æ–ª–æ–≤):")
            output.append("-" * 70)

            # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è preview
            text = metadata['text']
            if len(text) > 300:
                text = text[:300] + "..."

            output.append(text)
            output.append("")

        return "\n".join(output)


if __name__ == "__main__":
    # –¢–µ—Å—Ç –º–æ–¥—É–ª—è
    print("üß™ –¢–µ—Å—Ç –º–æ–¥—É–ª—è –ø–æ–∏—Å–∫–∞\n")

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: 3 –≤–µ–∫—Ç–æ—Ä–∞
    db_vectors = np.array([
        np.random.rand(384),  # –°–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä 1
        np.random.rand(384),  # –°–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä 2
        np.random.rand(384),  # –°–ª—É—á–∞–π–Ω—ã–π –≤–µ–∫—Ç–æ—Ä 3
    ])

    db_metadata = [
        {
            "id": 0,
            "timestamp": "2025-12-07T20:00:00",
            "screenshot_path": "screenshots/test1.png",
            "text": "Python - —ç—Ç–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è.",
            "text_length": 68,
        },
        {
            "id": 1,
            "timestamp": "2025-12-07T20:05:00",
            "screenshot_path": "screenshots/test2.png",
            "text": "Machine Learning - —Ä–∞–∑–¥–µ–ª –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, –∏–∑—É—á–∞—é—â–∏–π –º–µ—Ç–æ–¥—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤.",
            "text_length": 98,
        },
        {
            "id": 2,
            "timestamp": "2025-12-07T20:10:00",
            "screenshot_path": "screenshots/test3.png",
            "text": "Apple Silicon - —Å–µ–º–µ–π—Å—Ç–≤–æ ARM-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤ –æ—Ç Apple –¥–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–≤ Mac.",
            "text_length": 74,
        },
    ]

    # –ó–∞–ø—Ä–æ—Å: –≤–µ–∫—Ç–æ—Ä –±–ª–∏–∑–∫–∏–π –∫ –ø–µ—Ä–≤–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –±–∞–∑—ã
    query = db_vectors[0] + np.random.rand(384) * 0.1  # –ù–µ–º–Ω–æ–≥–æ —à—É–º–∞

    # –ü–æ–∏—Å–∫
    print("üîç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞...")
    results = VectorSearch.search(
        query_vector=query,
        database_vectors=db_vectors,
        database_metadata=db_metadata,
        top_k=3,
        threshold=0.5,
    )

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(VectorSearch.format_results(results))

    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω")
